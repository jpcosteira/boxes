{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8211dd81-c118-4b8d-8ef8-cceb8b63f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as futures\n",
    "import grpc\n",
    "import grpc_reflection.v1alpha.reflection as grpc_reflection\n",
    "import logging\n",
    "import simplebox_pb2\n",
    "import simplebox_pb2_grpc\n",
    "import inspect\n",
    "import os\n",
    "import time\n",
    "    \n",
    "import io\n",
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "\n",
    "\n",
    "_PORT_ENV_VAR = 'PORT'\n",
    "_PORT_DEFAULT = 8061\n",
    "_ONE_DAY_IN_SECONDS = 60 * 60 * 24\n",
    "\n",
    "\n",
    "class ServiceImpl(simplebox_pb2_grpc.SimpleBoxServiceServicer):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            \n",
    "          Loads VGGT model \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    " \n",
    "    # Initialize the model and load the pretrained weights.\n",
    "    # This will automatically download the model weights the first time it's run, which may take a while.\n",
    "        self._model = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)        \n",
    "        self._device = device\n",
    "\n",
    "\n",
    "\n",
    "    def process(self, request: simplebox_pb2.matfile, context):\n",
    "        \"\"\"\n",
    "        matfile is the matlab file with input data\n",
    "\n",
    "        Args:\n",
    "            request: The ImageAndFeatures request to process\n",
    "            context: Context of the gRPC call\n",
    "\n",
    "        Returns:\n",
    "            The Image with the applied function\n",
    "        features={'kp','desc'}\n",
    "        \"\"\"\n",
    "        datain = request.data\n",
    "\n",
    "        ret_file= run_codigo(datain, self._model,self._device)\n",
    "        return simplebox_pb2.matfile(data=ret_file)\n",
    "\n",
    "\n",
    "def run_codigo(datafile,model,device):\n",
    "    \"\"\"\n",
    "    Reads all variables from a MATLAB .mat file given a file pointer,\n",
    "    \n",
    "    Parameters:\n",
    "    file_pointer (file-like object): Opened .mat file in binary read mode.\n",
    "\n",
    "    Returns:\n",
    "    new_file_pointer (io.BytesIO): In-memory file-like object containing the cloned .mat file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # SPECIFIC CODE STARTS HERE\n",
    "\n",
    "    #Load the mat file using scipy.io.loadmat\n",
    "    mat_data=loadmat(io.BytesIO(datafile))\n",
    "\n",
    "        \n",
    "    # Extract and flatten the imgdata array\n",
    "    imgdata = mat_data['imgdata'].squeeze()\n",
    "\n",
    "    # List to hold in-memory files (as BytesIO) and their associated filenames\n",
    "    file_buffers = []\n",
    "    filenames = []\n",
    "\n",
    "    # Create in-memory files\n",
    "    for i, data in enumerate(imgdata):\n",
    "        #filename = f'image_{i+1}.jpg' uncomment if using regular files\n",
    "        # change next lines to save data on files and pass filenames in load_and_process_images\n",
    "        buffer = io.BytesIO()\n",
    "        buffer.write(data.flatten().tobytes())  # Write binary content to buffer\n",
    "        buffer.seek(0)  # Reset pointer to beginning for future reads\n",
    "        file_buffers.append(buffer)\n",
    "        filenames.append(filename)\n",
    "\n",
    "    images = load_and_preprocess_images(file_buffers).to(device)\n",
    "   # bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \n",
    "    dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(dtype=dtype):\n",
    "        # Predict attributes including cameras, depth maps, and point maps.\n",
    "            predictions = model(images)\n",
    "\n",
    "    p={}\n",
    "    for k,v in predictions.items():\n",
    "        p[k]=v.cpu()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    # SPECIFIC CODE ENDS HERE\n",
    "\n",
    "    f=io.BytesIO()\n",
    "    # WRITE RETURNING DATA the predictions dictionary\n",
    "    savemat(f,p)\n",
    "    return f.getvalue()\n",
    "\n",
    "def get_port():\n",
    "    \"\"\"\n",
    "    Parses the port where the server should listen\n",
    "    Exists the program if the environment variable\n",
    "    is not an int or the value is not positive\n",
    "\n",
    "    Returns:\n",
    "        The port where the server should listen or\n",
    "        None if an error occurred\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        server_port = int(os.getenv(_PORT_ENV_VAR, _PORT_DEFAULT))\n",
    "        if server_port <= 0:\n",
    "            logging.error('Port should be greater than 0')\n",
    "            return None\n",
    "        return server_port\n",
    "    except ValueError:\n",
    "        logging.exception('Unable to parse port')\n",
    "        return None\n",
    "\n",
    "def run_server(server):\n",
    "    \"\"\"Run the given server on the port defined\n",
    "    by the environment variables or the default port\n",
    "    if it is not defined\n",
    "\n",
    "    Args:\n",
    "        server: server to run\n",
    "\n",
    "    \"\"\"\n",
    "    port = get_port()\n",
    "    if not port:\n",
    "        return\n",
    "\n",
    "    target = f'[::]:{port}'\n",
    "    server.add_insecure_port(target)\n",
    "    server.start()\n",
    "    logging.info(f'''Server started at {target}''')\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(_ONE_DAY_IN_SECONDS)\n",
    "    except KeyboardInterrupt:\n",
    "        server.stop(0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc6356b-15fc-4a06-b619-9255f12baa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = grpc.server(futures.ThreadPoolExecutor(),\n",
    "                         options= [('grpc.max_send_message_length', 512 * 1024 * 1024), \n",
    "                                   ('grpc.max_receive_message_length', 512 * 1024 * 1024)])\n",
    "simplebox_pb2_grpc.add_SimpleBoxServiceServicer_to_server(ServiceImpl(), server)\n",
    "service_names = (simplebox_pb2.DESCRIPTOR.services_by_name['SimpleBoxService'].full_name,grpc_reflection.SERVICE_NAME)\n",
    "\n",
    "grpc_reflection.enable_server_reflection(service_names, server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b255e1-0217-4c53-96f1-0b259990fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_server(server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5611d224-e608-457d-9c88-2ab4cdbce010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _Server in module grpc._server object:\n",
      "\n",
      "class _Server(grpc.Server)\n",
      " |  _Server(thread_pool: 'futures.ThreadPoolExecutor', generic_handlers: 'Sequence[grpc.GenericRpcHandler]', interceptors: 'Sequence[grpc.ServerInterceptor]', options: 'Sequence[ChannelArgumentType]', maximum_concurrent_rpcs: 'Optional[int]', compression: 'Optional[grpc.Compression]', xds: 'bool')\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _Server\n",
      " |      grpc.Server\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __init__(self, thread_pool: 'futures.ThreadPoolExecutor', generic_handlers: 'Sequence[grpc.GenericRpcHandler]', interceptors: 'Sequence[grpc.ServerInterceptor]', options: 'Sequence[ChannelArgumentType]', maximum_concurrent_rpcs: 'Optional[int]', compression: 'Optional[grpc.Compression]', xds: 'bool')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add_generic_rpc_handlers(self, generic_rpc_handlers: 'Iterable[grpc.GenericRpcHandler]') -> 'None'\n",
      " |      Registers GenericRpcHandlers with this Server.\n",
      " |      \n",
      " |      This method is only safe to call before the server is started.\n",
      " |      \n",
      " |      Args:\n",
      " |        generic_rpc_handlers: An iterable of GenericRpcHandlers that will be\n",
      " |        used to service RPCs.\n",
      " |  \n",
      " |  add_insecure_port(self, address: 'str') -> 'int'\n",
      " |      Opens an insecure port for accepting RPCs.\n",
      " |      \n",
      " |      This method may only be called before starting the server.\n",
      " |      \n",
      " |      Args:\n",
      " |        address: The address for which to open a port. If the port is 0,\n",
      " |          or not specified in the address, then gRPC runtime will choose a port.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer port on which server will accept RPC requests.\n",
      " |  \n",
      " |  add_registered_method_handlers(self, service_name: 'str', method_handlers: 'Dict[str, grpc.RpcMethodHandler]') -> 'None'\n",
      " |      Registers GenericRpcHandlers with this Server.\n",
      " |      \n",
      " |      This method is only safe to call before the server is started.\n",
      " |      \n",
      " |      If the same method have both generic and registered handler,\n",
      " |      registered handler will take precedence.\n",
      " |      \n",
      " |      Args:\n",
      " |        service_name: The service name.\n",
      " |        method_handlers: A dictionary that maps method names to corresponding\n",
      " |          RpcMethodHandler.\n",
      " |  \n",
      " |  add_secure_port(self, address: 'str', server_credentials: 'grpc.ServerCredentials') -> 'int'\n",
      " |      Opens a secure port for accepting RPCs.\n",
      " |      \n",
      " |      This method may only be called before starting the server.\n",
      " |      \n",
      " |      Args:\n",
      " |        address: The address for which to open a port.\n",
      " |          if the port is 0, or not specified in the address, then gRPC\n",
      " |          runtime will choose a port.\n",
      " |        server_credentials: A ServerCredentials object.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer port on which server will accept RPC requests.\n",
      " |  \n",
      " |  start(self) -> 'None'\n",
      " |      Starts this Server.\n",
      " |      \n",
      " |      This method may only be called once. (i.e. it is not idempotent).\n",
      " |  \n",
      " |  stop(self, grace: 'Optional[float]') -> 'threading.Event'\n",
      " |      Stops this Server.\n",
      " |      \n",
      " |      This method immediately stop service of new RPCs in all cases.\n",
      " |      \n",
      " |      If a grace period is specified, this method waits until all active\n",
      " |      RPCs are finished or until the grace period is reached. RPCs that haven't\n",
      " |      been terminated within the grace period are aborted.\n",
      " |      If a grace period is not specified (by passing None for `grace`),\n",
      " |      all existing RPCs are aborted immediately and this method\n",
      " |      blocks until the last RPC handler terminates.\n",
      " |      \n",
      " |      This method is idempotent and may be called at any time.\n",
      " |      Passing a smaller grace value in a subsequent call will have\n",
      " |      the effect of stopping the Server sooner (passing None will\n",
      " |      have the effect of stopping the server immediately). Passing\n",
      " |      a larger grace value in a subsequent call *will not* have the\n",
      " |      effect of stopping the server later (i.e. the most restrictive\n",
      " |      grace value is used).\n",
      " |      \n",
      " |      Args:\n",
      " |        grace: A duration of time in seconds or None.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A threading.Event that will be set when this Server has completely\n",
      " |        stopped, i.e. when running RPCs either complete or are aborted and\n",
      " |        all handlers have terminated.\n",
      " |  \n",
      " |  wait_for_termination(self, timeout: 'Optional[float]' = None) -> 'bool'\n",
      " |      Block current thread until the server stops.\n",
      " |      \n",
      " |      This is an EXPERIMENTAL API.\n",
      " |      \n",
      " |      The wait will not consume computational resources during blocking, and\n",
      " |      it will block until one of the two following conditions are met:\n",
      " |      \n",
      " |      1) The server is stopped or terminated;\n",
      " |      2) A timeout occurs if timeout is not `None`.\n",
      " |      \n",
      " |      The timeout argument works in the same way as `threading.Event.wait()`.\n",
      " |      https://docs.python.org/3/library/threading.html#threading.Event.wait\n",
      " |      \n",
      " |      Args:\n",
      " |        timeout: A floating point number specifying a timeout for the\n",
      " |          operation in seconds.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A bool indicates if the operation times out.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_state': '_ServerState'}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from grpc.Server:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01591a9-31bc-4335-a63d-8d7de58a7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(\n",
    "        format='[ %(levelname)s ] %(asctime)s (%(module)s) %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO)\n",
    "    #Create Server and add service\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(),\n",
    "                         options= [('grpc.max_send_message_length', 512 * 1024 * 1024), \n",
    "                                   ('grpc.max_receive_message_length', 512 * 1024 * 1024)])\n",
    "    simplebox_pb2_grpc.add_SimpleBoxServiceServicer_to_server(\n",
    "        ServiceImpl(), server)\n",
    "\n",
    "    # Add reflection\n",
    "    service_names = (\n",
    "        simplebox_pb2.DESCRIPTOR.services_by_name['SimpleBoxService'].full_name,\n",
    "        grpc_reflection.SERVICE_NAME\n",
    "    )\n",
    "    grpc_reflection.enable_server_reflection(service_names, server)\n",
    "\n",
    "    run_server(server)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
